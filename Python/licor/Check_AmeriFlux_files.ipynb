{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/Users/bhupendra/projects/crocus/data/flux_data/data/AmeriFlux/US-CU1_HH_202409010000_202410010000.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"TIMESTAMP_START\"] = pd.to_datetime(df[\"TIMESTAMP_START\"], format=\"%Y%m%d%H%M\")\n",
    "df[\"TIMESTAMP_END\"] = pd.to_datetime(df[\"TIMESTAMP_END\"], format=\"%Y%m%d%H%M\")\n",
    "\n",
    "df_backup = df.copy() # saving for later use of original df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate variable names found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# QA/QC Checks\n",
    "\n",
    "# 1. Check for duplicate variable names\n",
    "duplicate_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "if duplicate_columns:\n",
    "    print(f\"Duplicate column names found: {duplicate_columns}\")\n",
    "else:\n",
    "    print(\"No duplicate variable names found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required timestamp columns are present.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Check if timestamp columns exist\n",
    "expected_timestamps = [\"TIMESTAMP_START\", \"TIMESTAMP_END\"]\n",
    "missing_timestamps = [col for col in expected_timestamps if col not in df.columns]\n",
    "if missing_timestamps:\n",
    "    print(f\"Missing timestamp columns: {missing_timestamps}\")\n",
    "else:\n",
    "    print(\"All required timestamp columns are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps in TIMESTAMP_START are in the correct format.\n",
      "Timestamps in TIMESTAMP_END are in the correct format.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Validate timestamp format\n",
    "for col in expected_timestamps:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], format=\"%Y%m%d%H%M\")\n",
    "            print(f\"Timestamps in {col} are in the correct format.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Timestamp format error in {col}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NAN values found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_vars = missing_values[missing_values > 0]\n",
    "if not missing_vars.empty:\n",
    "    print(f\"NAN values found in columns:\\n{missing_vars}\")\n",
    "else:\n",
    "    print(\"No NAN values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time is 2024-09-01 00:00:00 and end time is 2024-10-01 00:00:00\n",
      "time difference is 30 days 00:00:00\n",
      "number of rows are not correct. Missing 1 timesteps.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert timestamp columns to datetime\n",
    "df = df.sort_values(by=\"TIMESTAMP_START\")\n",
    "df[\"START\"] = pd.to_datetime(df[\"TIMESTAMP_START\"], format=\"%Y%m%d%H%M\")\n",
    "df[\"END\"] = pd.to_datetime(df[\"TIMESTAMP_END\"], format=\"%Y%m%d%H%M\")\n",
    "\n",
    "print(f\"start time is {df['START'].iloc[0]} and end time is {df['END'].iloc[-1]}\")\n",
    "period =  df['END'].iloc[-1] - df['START'].iloc[0]\n",
    "print(f\"time difference is {period}\")\n",
    "exp_num_of_rows = period/pd.Timedelta(minutes=30) \n",
    "num_of_rows = len(df)\n",
    "if exp_num_of_rows == num_of_rows:\n",
    "    print(\"number of rows are correct. No missing timesteps\")\n",
    "else:\n",
    "    missing_rows = exp_num_of_rows - num_of_rows\n",
    "    print(f\"number of rows are not correct. Missing {int(missing_rows)} timesteps.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2024-09-01 00:00:00             NaT\n",
      "1421 2024-09-30 15:00:00 0 days 01:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate expected time difference\n",
    "expected_time_diff = pd.Timedelta(minutes=30)\n",
    "\n",
    "# 1. Check for time gaps between consecutive rows\n",
    "df[\"time_diff\"] = df[\"TIMESTAMP_START\"].diff()\n",
    "gap_rows = df[df[\"time_diff\"] != expected_time_diff]\n",
    "if not gap_rows.empty:\n",
    "    print(f\"Time gaps detected in data:\\n{gap_rows[['TIMESTAMP_START', 'time_diff']]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time interval is 0 days 00:30:02.503477051, which is not 30 minutes.\n",
      "Time step checks completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Check if (Last TIMESTAMP_END - First TIMESTAMP_START) / Total Rows = 30 min\n",
    "total_duration = df[\"TIMESTAMP_END\"].iloc[-1] - df[\"TIMESTAMP_START\"].iloc[0]\n",
    "average_interval = total_duration / (len(df) - 1)  # -1 to get the intervals\n",
    "if average_interval != expected_time_diff:\n",
    "    print(f\"Average time interval is {average_interval}, which is not 30 minutes.\")\n",
    "else:\n",
    "    print(\"Time interval check passed: 30 minutes per row.\")\n",
    "\n",
    "print(\"Time step checks completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Some AmeriFlux variables, which may be required: ['CH4', 'CH4_MIXING_RATIO', 'CO', 'CO2_SIGMA', 'CO2C13', 'FCH4', 'FN2O', 'FNO', 'FNO2', 'FO3', 'H2O_SIGMA', 'N2O', 'N2O_MIXING_RATION', 'NO', 'NO2', 'O3', 'SC', 'SCH4', 'SN2O', 'SNO', 'SNO2', 'SO2', 'SO3', 'G', 'SB', 'SG', 'SH', 'SLE', 'SW_IN', 'SW_OUT', 'SC', 'SH', 'SLE']\n"
     ]
    }
   ],
   "source": [
    "# 6. Check if important AmeriFlux variables are present\n",
    "ameriflux_vars_imp = [\n",
    "    \"FETCH_70\", \"FETCH_80\", \"FETCH_90\", \"FETCH_MAX\", \"CH4\", \"CH4_MIXING_RATIO\", \"CO\", \"CO2\",\n",
    "    \"CO2_MIXING_RATIO\", \"CO2_SIGMA\", \"CO2C13\", \"FC\", \"FCH4\", \"FN2O\", \"FNO\", \"FNO2\", \"FO3\", \"H2O\",\n",
    "    \"H2O_MIXING_RATIO\", \"H2O_SIGMA\", \"N2O\", \"N2O_MIXING_RATION\", \"NO\", \"NO2\", \"O3\", \"SC\", \"SCH4\",\n",
    "    \"SN2O\", \"SNO\", \"SNO2\", \"SO2\", \"SO3\", \"FH2O\", \"G\", \"H\", \"LE\", \"SB\", \"SG\", \"SH\", \"SLE\", \"PA\",\n",
    "    \"RH\", \"T_SONIC\", \"T_SONIC_SIGMA\", \"TA\", \"VPD\", \"SW_IN\", \"SW_OUT\", \"PA\", \"TA\", \"RH\", \"VPD\", \"SC\", \"SH\", \"SLE\"\n",
    "]\n",
    "\n",
    "\n",
    "missing_vars = [var for var in ameriflux_vars_imp if var not in df.columns]\n",
    "if missing_vars:\n",
    "    print(f\"Missing Some AmeriFlux variables, which may be required: {missing_vars}\")\n",
    "else:\n",
    "    print(\"All required AmeriFlux variables are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Some AmeriFlux variables, which may not be required: ['TIMESTAMP', 'COND_WATER', 'DO', 'PCH4', 'PCO2', 'PN2O', 'PPFD_UW_IN', 'TW', 'DBH', 'LEAF_WET', 'SAP_DT', 'SAP_FLOW', 'T_BOLE', 'T_CANOPY', 'FETCH_FILTER', 'CH4', 'CH4_MIXING_RATIO', 'CO', 'CO2_SIGMA', 'CO2C13', 'FCH4', 'FN2O', 'FNO', 'FNO2', 'FO3', 'H2O_SIGMA', 'N2O', 'N2O_MIXING_RATION', 'NO', 'NO2', 'O3', 'SC', 'SCH4', 'SN2O', 'SNO', 'SNO2', 'SO2', 'SO3', 'G', 'SB', 'SG', 'SH', 'SLE', 'PBLH', 'D_SNOW', 'P', 'P_RAIN', 'P_SNOW', 'RUNOFF', 'STEMFLOW', 'THROUGHFALL', 'ALB', 'APAR', 'EVI', 'FAPAR', 'FIPAR', 'LW_BC_IN', 'LW_BC_OUT', 'LW_IN', 'LW_OUT', 'MCRI', 'MTCI', 'NDVI', 'NETRAD', 'NIRV', 'PPFD_BC_IN', 'PPFD_BC_OUT', 'PPFD_DIF', 'PPFD_DIR', 'PPFD_IN', 'PPFD_OUT', 'PRI', 'R_UVA', 'R_UVB', 'REDCIRed', 'REP', 'SPEC_NIR_IN', 'SPEC_NIR_OUT', 'SPEC_NIR_REFL', 'SPEC_PRI_REF_IN', 'SPEC_PRI_REF_OUT', 'SPEC_PRI_REF_REFL', 'SPEC_PRI_TGT_IN', 'SPEC_PRI_TGT_OUT', 'SPEC_PRI_TGT_REFL', 'SPEC_RED_IN', 'SPEC_RED_OUT', 'SPEC_RED_REFL', 'SR', 'SW_BC_IN', 'SW_BC_OUT', 'SW_DIF', 'SW_DIR', 'SW_IN', 'SW_OUT', 'TCARI', 'SWC', 'SWP', 'TS', 'TNS', 'WTD', 'GPP', 'NEE', 'RECO', 'FCH4_SSITC_TEST', 'FN2O_SSITC_TEST', 'FNO_SSITC_TEST', 'FNO2_SSITC_TEST', 'FO3_SSITC_TEST']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Check if all required AmeriFlux variables are present\n",
    "ameriflux_vars = [\n",
    "    \"TIMESTAMP_START\", \"TIMESTAMP_END\", \"TIMESTAMP\", \"COND_WATER\", \"DO\", \"PCH4\", \"PCO2\", \"PN2O\",\n",
    "    \"PPFD_UW_IN\", \"TW\", \"DBH\", \"LEAF_WET\", \"SAP_DT\", \"SAP_FLOW\", \"T_BOLE\", \"T_CANOPY\", \"FETCH_70\",\n",
    "    \"FETCH_80\", \"FETCH_90\", \"FETCH_FILTER\", \"FETCH_MAX\", \"CH4\", \"CH4_MIXING_RATIO\", \"CO\", \"CO2\",\n",
    "    \"CO2_MIXING_RATIO\", \"CO2_SIGMA\", \"CO2C13\", \"FC\", \"FCH4\", \"FN2O\", \"FNO\", \"FNO2\", \"FO3\", \"H2O\",\n",
    "    \"H2O_MIXING_RATIO\", \"H2O_SIGMA\", \"N2O\", \"N2O_MIXING_RATION\", \"NO\", \"NO2\", \"O3\", \"SC\", \"SCH4\",\n",
    "    \"SN2O\", \"SNO\", \"SNO2\", \"SO2\", \"SO3\", \"FH2O\", \"G\", \"H\", \"LE\", \"SB\", \"SG\", \"SH\", \"SLE\", \"PA\",\n",
    "    \"PBLH\", \"RH\", \"T_SONIC\", \"T_SONIC_SIGMA\", \"TA\", \"VPD\", \"D_SNOW\", \"P\", \"P_RAIN\", \"P_SNOW\",\n",
    "    \"RUNOFF\", \"STEMFLOW\", \"THROUGHFALL\", \"ALB\", \"APAR\", \"EVI\", \"FAPAR\", \"FIPAR\", \"LW_BC_IN\",\n",
    "    \"LW_BC_OUT\", \"LW_IN\", \"LW_OUT\", \"MCRI\", \"MTCI\", \"NDVI\", \"NETRAD\", \"NIRV\", \"PPFD_BC_IN\",\n",
    "    \"PPFD_BC_OUT\", \"PPFD_DIF\", \"PPFD_DIR\", \"PPFD_IN\", \"PPFD_OUT\", \"PRI\", \"R_UVA\", \"R_UVB\",\n",
    "    \"REDCIRed\", \"REP\", \"SPEC_NIR_IN\", \"SPEC_NIR_OUT\", \"SPEC_NIR_REFL\", \"SPEC_PRI_REF_IN\",\n",
    "    \"SPEC_PRI_REF_OUT\", \"SPEC_PRI_REF_REFL\", \"SPEC_PRI_TGT_IN\", \"SPEC_PRI_TGT_OUT\",\n",
    "    \"SPEC_PRI_TGT_REFL\", \"SPEC_RED_IN\", \"SPEC_RED_OUT\", \"SPEC_RED_REFL\", \"SR\", \"SW_BC_IN\",\n",
    "    \"SW_BC_OUT\", \"SW_DIF\", \"SW_DIR\", \"SW_IN\", \"SW_OUT\", \"TCARI\", \"SWC\", \"SWP\", \"TS\", \"TNS\", \"WTD\",\n",
    "    \"MO_LENGTH\", \"TAU\", \"U_SIGMA\", \"USTAR\", \"V_SIGMA\", \"W_SIGMA\", \"WD\", \"WD_SIGMA\", \"WS\", \"WS_MAX\",\n",
    "    \"ZL\", \"GPP\", \"NEE\", \"RECO\", \"FC_SSITC_TEST\", \"FCH4_SSITC_TEST\", \"FN2O_SSITC_TEST\",\n",
    "    \"FNO_SSITC_TEST\", \"FNO2_SSITC_TEST\", \"FO3_SSITC_TEST\", \"H_SSITC_TEST\", \"LE_SSITC_TEST\",\n",
    "    \"TAU_SSITC_TEST\"\n",
    "]\n",
    "\n",
    "\n",
    "missing_vars = [var for var in ameriflux_vars if var not in df.columns]\n",
    "if missing_vars:\n",
    "    print(f\"Missing Some AmeriFlux variables, which may not be required: {missing_vars}\")\n",
    "else:\n",
    "    print(\"All required AmeriFlux variables are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate timestamps found.\n",
      "QA/QC checks completed.\n"
     ]
    }
   ],
   "source": [
    "# 7. Check for duplicate timestamps\n",
    "duplicate_timestamps = df[\"TIMESTAMP_START\"].duplicated().sum()\n",
    "if duplicate_timestamps > 0:\n",
    "    print(f\"Duplicate timestamps found: {duplicate_timestamps}\")\n",
    "else: \n",
    "    print(\"No duplicate timestamps found.\")\n",
    "\n",
    "print(\"QA/QC checks completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Standard AmeriFlux variables found: ['TIMESTAMP_START', 'TIMESTAMP_END', 'FETCH_70', 'FETCH_80', 'FETCH_90', 'FETCH_MAX', 'CO2', 'CO2_MIXING_RATIO', 'FC', 'H2O', 'H2O_MIXING_RATIO', 'FH2O', 'H', 'LE', 'PA', 'RH', 'T_SONIC', 'T_SONIC_SIGMA', 'TA', 'VPD', 'MO_LENGTH', 'TAU', 'U_SIGMA', 'USTAR', 'V_SIGMA', 'W_SIGMA', 'WD', 'WD_SIGMA', 'WS', 'WS_MAX', 'ZL', 'FC_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST']\n",
      "All variables in the file are AmeriFlux variables.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check which AmeriFlux variables are present\n",
    "present_vars = [var for var in ameriflux_vars if var in df_backup.columns]\n",
    "num_of_present_vars = len(present_vars)\n",
    "\n",
    "# Identify non-AmeriFlux variables\n",
    "non_ameriflux_vars = [var for var in df_backup.columns if var not in ameriflux_vars]\n",
    "num_of_non_ameriflux_vars = len(non_ameriflux_vars)\n",
    "\n",
    "if present_vars:\n",
    "    print(f\"{num_of_present_vars} Standard AmeriFlux variables found: {present_vars}\")\n",
    "else:\n",
    "    print(\"No standard AmeriFlux variables found.\")\n",
    "\n",
    "if num_of_non_ameriflux_vars == 0:\n",
    "    print(\"All variables in the file are AmeriFlux variables.\")\n",
    "else:\n",
    "    print(f\"{num_of_non_ameriflux_vars} variables in the file are not AmeriFlux variables: {non_ameriflux_vars}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: US-CU1_HH_202409010000_202410010000.csv\n",
      "✅ Filename format is correct.\n"
     ]
    }
   ],
   "source": [
    "# Get the filename for validation\n",
    "file_name = os.path.basename(file_path)\n",
    "print(f\"Filename: {file_name}\")\n",
    "# 1. Verify Filename Format\n",
    "filename_pattern = r\"^US-\\w{3}_HH_\\d{12}_\\d{12}(?:_[\\w\\d]+)?\\.csv$\"\n",
    "if re.match(filename_pattern, file_name):\n",
    "    print(\"✅ Filename format is correct.\")\n",
    "else:\n",
    "    print(\"❌ ERROR: Filename format is incorrect!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No quotes found in variable names.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Check for Quotes in Variable Names\n",
    "quoted_columns = [col for col in df.columns if col.startswith('\"') or col.endswith('\"')]\n",
    "if quoted_columns:\n",
    "    print(f\"❌ ERROR: Quotes found in column names: {quoted_columns}\")\n",
    "else:\n",
    "    print(\"✅ No quotes found in variable names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Timestamp headers are present.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Validate Timestamp Headers\n",
    "expected_timestamps = [\"TIMESTAMP_START\", \"TIMESTAMP_END\"]\n",
    "missing_timestamps = [col for col in expected_timestamps if col not in df.columns]\n",
    "if missing_timestamps:\n",
    "    print(f\"❌ ERROR: Missing timestamp headers: {missing_timestamps}\")\n",
    "else:\n",
    "    print(\"✅ Timestamp headers are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202410010000.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filename time components match file time period.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Check if Filename Time Components Match File Time Period\n",
    "try:\n",
    "    start_time_from_filename = pd.to_datetime(file_name.split(\"_\")[2], format=\"%Y%m%d%H%M\")\n",
    "    end_time_from_filename = pd.to_datetime(file_name.split(\"_\")[3].split(\".\")[0], format=\"%Y%m%d%H%M\")\n",
    "    \n",
    "    df[\"TIMESTAMP_START\"] = pd.to_datetime(df[\"TIMESTAMP_START\"], format=\"%Y%m%d%H%M\")\n",
    "    df[\"TIMESTAMP_END\"] = pd.to_datetime(df[\"TIMESTAMP_END\"], format=\"%Y%m%d%H%M\")\n",
    "    \n",
    "\n",
    "    if df[\"TIMESTAMP_START\"].iloc[0] == start_time_from_filename and df[\"TIMESTAMP_END\"].iloc[-1] == end_time_from_filename:\n",
    "        print(\"✅ Filename time components match file time period.\")\n",
    "    else:\n",
    "        print(\"❌ ERROR: Filename time components do NOT match file time period!\")\n",
    "        print(f\"Expected Start Time: {start_time_from_filename}, Actual Start Time: {df['TIMESTAMP_START'].iloc[0]}\")\n",
    "        print(f\"Expected End Time: {end_time_from_filename}, Actual End Time: {df['TIMESTAMP_END'].iloc[-1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR in matching filename time components: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "QA/QC checks completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Detect Missing or Gap-Filled Data\n",
    "missing_values = df.isnull().sum()\n",
    "missing_vars = missing_values[missing_values > 0].index.tolist()\n",
    "if missing_vars:\n",
    "    print(f\"⚠️ WARNING: Missing values found in columns: {missing_vars}\")\n",
    "else:\n",
    "    print(\"✅ No missing values found.\")\n",
    "\n",
    "all_missing_vars = [col for col in df.columns if df[col].isnull().all()]\n",
    "if all_missing_vars:\n",
    "    print(f\"❌ ERROR: Variables with ALL missing data: {all_missing_vars}\")\n",
    "else:\n",
    "    print(\"✅ No variables have all missing data.\")\n",
    "\n",
    "print(\"QA/QC checks completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# QA/QC Report for **US-CU1_HH_202410010000_202411010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2024-10-01 00:00:00             NaT\n",
      "91   2024-10-02 22:00:00 0 days 01:00:00\n",
      "458  2024-10-10 14:00:00 0 days 01:00:00\n",
      "1246 2024-10-27 00:30:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202412010000_202501010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "        TIMESTAMP_START       time_diff\n",
      "0   2024-12-01 00:00:00             NaT\n",
      "916 2024-12-20 06:00:00 0 days 04:30:00\n",
      "925 2024-12-20 12:00:00 0 days 02:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202502010000_202502180200.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "        TIMESTAMP_START       time_diff\n",
      "0   2025-02-01 00:00:00             NaT\n",
      "248 2025-02-06 04:30:00 0 days 01:00:00\n",
      "249 2025-02-06 06:00:00 0 days 01:30:00\n",
      "250 2025-02-06 07:00:00 0 days 01:00:00\n",
      "588 2025-02-13 18:00:00 0 days 10:30:00\n",
      "635 2025-02-14 18:00:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202501010000_202502010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2025-01-01 00:00:00             NaT\n",
      "2    2025-01-01 01:30:00 0 days 01:00:00\n",
      "1366 2025-01-29 12:00:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202411010000_202412010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2024-11-01 00:00:00             NaT\n",
      "1217 2024-11-26 09:00:00 0 days 01:00:00\n",
      "1345 2024-11-29 01:30:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202407010000_202408010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2024-07-01 00:00:00             NaT\n",
      "809  2024-07-17 21:00:00 0 days 01:00:00\n",
      "1198 2024-07-26 00:00:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202408010000_202409010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "        TIMESTAMP_START       time_diff\n",
      "0   2024-08-01 00:00:00             NaT\n",
      "120 2024-08-03 12:30:00 0 days 01:00:00\n",
      "250 2024-08-06 06:00:00 0 days 01:00:00\n",
      "953 2024-08-27 15:30:00 6 days 18:30:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n",
      "# QA/QC Report for **US-CU1_HH_202409010000_202410010000.csv**\n",
      "_Generated on 2025-02-22 18:11:28_\n",
      "\n",
      "### Filename Check\n",
      "✅ Filename format is correct.\n",
      "\n",
      "### Variable Header Checks\n",
      "✅ No duplicate variable names found.\n",
      "✅ No quotes found in variable names.\n",
      "\n",
      "### Timestamp Header Checks\n",
      "✅ All required timestamp columns are present.\n",
      "✅ Timestamps in TIMESTAMP_START are in the correct format.\n",
      "✅ Timestamps in TIMESTAMP_END are in the correct format.\n",
      "\n",
      "### Filename Time Consistency Check\n",
      "✅ Filename time components match file time period.\n",
      "\n",
      "### Missing Data Check\n",
      "✅ No missing values found.\n",
      "✅ No variables have all missing data.\n",
      "\n",
      "### Time Gap Check\n",
      "⚠️ WARNING: Time gaps detected in data:\n",
      "         TIMESTAMP_START       time_diff\n",
      "0    2024-09-01 00:00:00             NaT\n",
      "1421 2024-09-30 15:00:00 0 days 01:00:00\n",
      "\n",
      "### AmeriFlux Variable Check\n",
      "✅ All required AmeriFlux variables are present.\n",
      "\n",
      "✅ **QA/QC Checks Completed Successfully** ✅\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from datetime import datetime\n",
    "data_dir = \"/Users/bhupendra/projects/crocus/data/flux_data/data/AmeriFlux/\"\n",
    "\n",
    "# Configure logging\n",
    "\n",
    "def setup_logger():\n",
    "    file_name = \"Ameriflux_filecheck.log\"\n",
    "    \"\"\"Setup logger for a specific file.\"\"\"\n",
    "    log_file = os.path.join(data_dir, file_name)\n",
    "    logger = logging.getLogger(log_file)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Clear existing handlers\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    # Create handlers\n",
    "    handler = logging.FileHandler(log_file, mode='w')\n",
    "    handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    # Also print logs to console\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "\n",
    "def check_filename(file_name, logger):\n",
    "    \"\"\"Check if the filename matches the expected AmeriFlux format.\"\"\"\n",
    "    logger.info(\"### Filename Check\")\n",
    "    filename_pattern = r\"^US-\\w{3}_HH_\\d{12}_\\d{12}(?:_[\\w\\d]+)?\\.csv$\"\n",
    "    if re.match(filename_pattern, file_name):\n",
    "        logger.info(\"✅ Filename format is correct.\")\n",
    "    else:\n",
    "        logger.error(\"❌ ERROR: Filename format is incorrect!\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_variable_headers(df, logger):\n",
    "    \"\"\"Check for duplicate and quoted variable names.\"\"\"\n",
    "    logger.info(\"### Variable Header Checks\")\n",
    "    \n",
    "    # Duplicate column names\n",
    "    duplicate_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "    if duplicate_columns:\n",
    "        logger.warning(f\"⚠️ WARNING: Duplicate column names found: {duplicate_columns}\")\n",
    "    else:\n",
    "        logger.info(\"✅ No duplicate variable names found.\")\n",
    "\n",
    "    # Check for quotes in variable names\n",
    "    quoted_columns = [col for col in df.columns if col.startswith('\"') or col.endswith('\"')]\n",
    "    if quoted_columns:\n",
    "        logger.error(f\"❌ ERROR: Quotes found in column names: {quoted_columns}\")\n",
    "    else:\n",
    "        logger.info(\"✅ No quotes found in variable names.\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_timestamp_headers(df, logger):\n",
    "    \"\"\"Validate timestamp headers and format.\"\"\"\n",
    "    logger.info(\"### Timestamp Header Checks\")\n",
    "    \n",
    "    expected_timestamps = [\"TIMESTAMP_START\", \"TIMESTAMP_END\"]\n",
    "    missing_timestamps = [col for col in expected_timestamps if col not in df.columns]\n",
    "    \n",
    "    if missing_timestamps:\n",
    "        logger.error(f\"❌ ERROR: Missing timestamp headers: {missing_timestamps}\")\n",
    "    else:\n",
    "        logger.info(\"✅ All required timestamp columns are present.\")\n",
    "\n",
    "        # Check format\n",
    "        for col in expected_timestamps:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], format=\"%Y%m%d%H%M\")\n",
    "                logger.info(f\"✅ Timestamps in {col} are in the correct format.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ ERROR: Timestamp format error in {col}: {e}\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_filename_time_consistency(df, file_name, logger):\n",
    "    \"\"\"Check if the filename time components match the file's time period.\"\"\"\n",
    "    logger.info(\"### Filename Time Consistency Check\")\n",
    "\n",
    "    try:\n",
    "        start_time_from_filename = pd.to_datetime(file_name.split(\"_\")[2], format=\"%Y%m%d%H%M\")\n",
    "        end_time_from_filename = pd.to_datetime(file_name.split(\"_\")[3].split(\".\")[0], format=\"%Y%m%d%H%M\")\n",
    "\n",
    "        actual_start_time = df[\"TIMESTAMP_START\"].iloc[0]\n",
    "        actual_end_time = df[\"TIMESTAMP_END\"].iloc[-1]\n",
    "\n",
    "        if actual_start_time == start_time_from_filename and actual_end_time == end_time_from_filename:\n",
    "            logger.info(\"✅ Filename time components match file time period.\")\n",
    "        else:\n",
    "            logger.error(\"❌ ERROR: Filename time components do NOT match file time period!\")\n",
    "            logger.error(f\"Expected Start Time: {start_time_from_filename}, Actual Start Time: {actual_start_time}\")\n",
    "            logger.error(f\"Expected End Time: {end_time_from_filename}, Actual End Time: {actual_end_time}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ ERROR in matching filename time components: {e}\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_missing_values(df, logger):\n",
    "    \"\"\"Check for missing values in the dataset.\"\"\"\n",
    "    logger.info(\"### Missing Data Check\")\n",
    "    \n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_vars = missing_values[missing_values > 0].index.tolist()\n",
    "    \n",
    "    if missing_vars:\n",
    "        logger.warning(f\"⚠️ WARNING: Missing values found in columns: {missing_vars}\")\n",
    "    else:\n",
    "        logger.info(\"✅ No missing values found.\")\n",
    "\n",
    "    all_missing_vars = [col for col in df.columns if df[col].isnull().all()]\n",
    "    if all_missing_vars:\n",
    "        logger.error(f\"❌ ERROR: Variables with ALL missing data: {all_missing_vars}\")\n",
    "    else:\n",
    "        logger.info(\"✅ No variables have all missing data.\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_time_gaps(df, logger):\n",
    "    \"\"\"Check for time gaps between consecutive rows.\"\"\"\n",
    "    logger.info(\"### Time Gap Check\")\n",
    "\n",
    "    expected_time_diff = pd.Timedelta(minutes=30)\n",
    "    df[\"time_diff\"] = df[\"TIMESTAMP_START\"].diff()\n",
    "    gap_rows = df[df[\"time_diff\"] != expected_time_diff]\n",
    "\n",
    "    if not gap_rows.empty:\n",
    "        logger.warning(f\"⚠️ WARNING: Time gaps detected in data:\\n{gap_rows[['TIMESTAMP_START', 'time_diff']]}\")\n",
    "    else:\n",
    "        logger.info(\"✅ No time gaps detected.\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def check_required_variables(df, logger):\n",
    "    \"\"\"Check if all required AmeriFlux variables are present.\"\"\"\n",
    "    logger.info(\"### AmeriFlux Variable Check\")\n",
    "\n",
    "    ameriflux_vars = [\"CO2\", \"H2O\", \"LE\", \"H\", \"TA\", \"PA\", \"RH\", \"VPD\", \"FC\"]\n",
    "    missing_vars = [var for var in ameriflux_vars if var not in df.columns]\n",
    "\n",
    "    if missing_vars:\n",
    "        logger.warning(f\"⚠️ WARNING: Missing Some Required AmeriFlux Variables: {missing_vars}\")\n",
    "    else:\n",
    "        logger.info(\"✅ All required AmeriFlux variables are present.\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process a single AmeriFlux CSV file and run QA/QC checks.\"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    logger.info(f\"# QA/QC Report for **{file_name}**\")\n",
    "    logger.info(f\"_Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_\\n\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    check_filename(file_name, logger)\n",
    "    check_variable_headers(df, logger)\n",
    "    check_timestamp_headers(df, logger)\n",
    "    check_filename_time_consistency(df, file_name, logger)\n",
    "    check_missing_values(df, logger)\n",
    "    check_time_gaps(df, logger)\n",
    "    check_required_variables(df, logger)\n",
    "\n",
    "    logger.info(\"✅ **QA/QC Checks Completed Successfully** ✅\\n\")\n",
    "    logger.info(\"---\\n\")\n",
    "def process_directory(directory):\n",
    "    \"\"\"Process all AmeriFlux CSV files in a directory.\"\"\"\n",
    "    csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"❌ No CSV files found in the directory!\")\n",
    "        return\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        process_file(file_path)\n",
    "\n",
    "# Run QA/QC on a directory\n",
    "logger = setup_logger()\n",
    "process_directory(data_dir)\n",
    "logger.handlers.clear()  # Close the logger after processing\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
